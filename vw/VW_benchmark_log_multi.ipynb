{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MNIST classification with Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found some help with parameters here: \n",
    "* https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial    \n",
    "* https://github.com/JohnLangford/vowpal_wabbit/wiki/Command-line-arguments\n",
    "\n",
    "--cache_file train.cache    \n",
    "converts train_ALL.vw to a binary file for future faster processing. \n",
    "Next time we go through the model building, we will use the cache file \n",
    "and not the text file.    \n",
    "\n",
    "--passes     \n",
    "is the number of passes    \n",
    "\n",
    "--oaa 10    \n",
    "refers to oaa learning algorithm with 10 classes (1 to 10)    \n",
    "\n",
    "-q ii    \n",
    "creates interaction between variables in the two referred to namespaces \n",
    "which here are the same i.e. 'image' Namespace.   \n",
    "An interaction variable is created from two variables 'A' and 'B' \n",
    "by multiplying the values of 'A' and 'B'.    \n",
    "\n",
    "-f mnist_ALL.model    \n",
    "refers to file where model will be saved.    \n",
    "\n",
    "-b     \n",
    "refers to number of bits in the feature table.   \n",
    "Default number is 18 but as we have increased the number of features much more \n",
    "by introducing interaction features, value of '-b' has been increased to 22.   \n",
    "\n",
    "-l rate   \n",
    "Adjust the learning rate. Defaults to 0.5\n",
    "\n",
    "--power_t p   \n",
    "This specifies the power on the learning rate decay. You can adjust this --power_t p where p is in the range [0,1]. 0 means the learning rate does not decay, which can be helpful when state tracking, while 1 is very aggressive. Defaults to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘train_logmulti.vw.cache’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm train_logmulti.vw.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘mnist_train_logmulti.model’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm mnist_train_logmulti.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: ii \n",
      "final_regressor = mnist_train_logmulti.model\n",
      "Num weight bits = 19\n",
      "learning rate = 0.4\n",
      "initial_t = 0\n",
      "power_t = 0.6\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train_logmulti.vw.cache\n",
      "Reading datafile = data/mnist_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        6        1    14028\n",
      "1.000000 1.000000            2            2.0        1        6    15753\n",
      "1.000000 1.000000            4            4.0        2        6     4753\n",
      "1.000000 1.000000            8            8.0        4        3    20301\n",
      "0.812500 0.625000           16           16.0        3        2    11476\n",
      "0.843750 0.875000           32           32.0        1       10    17020\n",
      "0.687500 0.531250           64           64.0        2        2     7626\n",
      "0.531250 0.375000          128          128.0        8        9     8646\n",
      "0.476562 0.421875          256          256.0        1        1    27730\n",
      "0.382812 0.289062          512          512.0        8        8     6786\n",
      "0.313477 0.244141         1024         1024.0        7        7    14878\n",
      "0.226074 0.138672         2048         2048.0       10       10     9316\n",
      "0.171875 0.117676         4096         4096.0        3        3     9316\n",
      "0.131836 0.091797         8192         8192.0        1        1    14365\n",
      "0.104431 0.077026        16384        16384.0        5        5    10585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!vw -d data/mnist_train.vw -b 19  --ect 10  -f mnist_train_logmulti.model  -q ii  --passes 100 -l 0.4  --early_terminate 3  --cache_file train_logmulti.vw.cache --power_t 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Predict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-t    \n",
    "is for test file   \n",
    "\n",
    "-i    \n",
    "specifies the model file created earlier   \n",
    "\n",
    "-p   \n",
    "where to store the class predictions [1,10]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm predict_logmulti.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -t data/mnist_test.vw -i mnist_train_logmulti.model  -p predict_logmulti.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true=[]\n",
    "with open(\"data/mnist_test.vw\", 'rb') as f:\n",
    "    for line in f:\n",
    "        m = re.search('^\\d+', line)\n",
    "        if m:\n",
    "            found = m.group()\n",
    "        y_true.append(int(found))\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "with open(\"predict_logmulti.txt\", 'rb') as f:\n",
    "    for line in f:\n",
    "        m = re.search('^\\d+', line)\n",
    "        if m:\n",
    "            found = m.group()\n",
    "        y_pred.append(int(found))\n",
    "\n",
    "target_names     = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"] # NOTE: plus one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, \n",
    "                          target_names,\n",
    "                          title='Proportional Confusion matrix: VW log_multi on 784 pixels', \n",
    "                          cmap=plt.cm.Paired):  \n",
    "    \"\"\"\n",
    "    given a confusion matrix (cm), make a nice plot\n",
    "    see the skikit-learn documentation for the original done for the iris dataset\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow((cm/cm.sum(axis=1)), interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "cm = confusion_matrix(y_true, y_pred)  \n",
    "\n",
    "print(cm)\n",
    "model_accuracy = sum(cm.diagonal())/len(y_pred)\n",
    "model_misclass = 1 - model_accuracy\n",
    "print(\"\\nModel accuracy: {0}, model misclass rate: {1}\".format(model_accuracy, model_misclass))\n",
    "\n",
    "plot_confusion_matrix(cm, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
